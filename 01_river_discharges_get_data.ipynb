{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "039f3d6d",
   "metadata": {},
   "source": [
    "# Hazard assessment for river flooding using river discharge statistics\n",
    "## Accessing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead1dcbd",
   "metadata": {},
   "source": [
    "This notebook illustrates how the river discharges dataset can be downloaded via API from the Copernicus Data Store for subsequent use in the analysis. The dataset is downloaded for the entire Europe, it is not possible to subset it by area prior to downloading. \n",
    "\n",
    "Note: alternatively it is possible to access this dataset via the dataset mirror on the CLIMAAX data server, this option is made available to speed up data access. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81b4937",
   "metadata": {},
   "source": [
    "### Load libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb46ba4e",
   "metadata": {},
   "source": [
    "`````{admonition} Find more info about the libraries used in this workflow here\n",
    ":class: hint dropdown\n",
    "\n",
    "In this notebook we will use the following Python libraries:\n",
    "- [os](https://docs.python.org/3/library/os.html) - Provides a way to interact with the operating system, allowing the creation of directories and file manipulation.\n",
    "- [xarray](https://docs.xarray.dev/en/stable/) - library for working with labelled multi-dimensional arrays.\n",
    "- cdsapi\n",
    "- zipfile\n",
    "\n",
    "These libraries enable the download of the dataset.\n",
    "`````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be75a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import cdsapi\n",
    "import zipfile\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd7e4d7",
   "metadata": {},
   "source": [
    "### Create the directory structure\n",
    "In the next cell will create the directory called 'FLOOD_RIVER_discharges' in the same directory where this notebook is saved. A folder for storing data will be made as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3783fef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the folder for the flood workflow\n",
    "workflow_folder = 'FLOOD_RIVER_discharges'\n",
    "os.makedirs(workflow_folder, exist_ok=True)\n",
    "\n",
    "#data_folder = os.path.join(workflow_folder, 'data')\n",
    "data_folder = r'n:\\My Documents\\projects\\CLIMAAX\\River_discharges\\FLOOD_RIVER_discharges\\data' # TEMP\n",
    "os.makedirs(data_folder, exist_ok=True)\n",
    "\n",
    "data_folder_catch = os.path.join(data_folder, 'EHYPEcatch')\n",
    "os.makedirs(data_folder_catch, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5439265c",
   "metadata": {},
   "source": [
    "### Data access parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e945289",
   "metadata": {},
   "source": [
    "In the cell below we will select three GCM-RCM model combinations (see dataset documentation for the available combinations). Using several model combinations helps to assess the uncertainty range due to the different climate models in the river discharges data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdddd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcms = [\"ec_earth\",\"hadgem2_es\",\"mpi_esm_lr\"]\n",
    "rcms = [\"racmo22e\",\"rca4\",\"csc_remo2009\"]\n",
    "ens_members = ['r12i1p1','r1i1p1','r1i1p1']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82a9e5c",
   "metadata": {},
   "source": [
    "We also need to initialize the API client to be able to make connection to the CDS servers for downloading the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71825214",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = cdsapi.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0189f73f",
   "metadata": {},
   "source": [
    "### Downloading river discharge timeseries - historical daily values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0251f2de",
   "metadata": {},
   "source": [
    "First we will download catchment-level discharge data for the historical period. Data is available based on different E-HYPEcatch model realizations. We will download all model realizations.\n",
    "\n",
    "The daily timeseries are downloaded for the period of 2000-2005. If a different period is required for comparing to local observations, the selection can be adjusted below as part of the API request under \"period\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0989bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-23 16:28:30,401 INFO [2025-01-29T00:00:00] This dataset is no longer supported by the data providers. Data and documentation are provided as is. Users are encouraged to use our [Forum](https://forum.ecmwf.int/) to raise any item of discussion with respect to this dataset.\n",
      "2025-07-23 16:28:30,402 INFO Request ID is 8ded3f52-88c2-494c-97e7-928cddba03ae\n",
      "2025-07-23 16:28:30,538 INFO status has been updated to accepted\n",
      "2025-07-23 16:29:20,362 INFO status has been updated to running\n",
      "2025-07-23 16:42:49,984 INFO status has been updated to successful\n",
      "2025-07-23 16:43:34,731 INFO [2025-01-29T00:00:00] This dataset is no longer supported by the data providers. Data and documentation are provided as is. Users are encouraged to use our [Forum](https://forum.ecmwf.int/) to raise any item of discussion with respect to this dataset.\n",
      "2025-07-23 16:43:34,732 INFO Request ID is a4f7230d-5855-427e-9435-e8a8e6d1c1cc\n",
      "2025-07-23 16:43:34,810 INFO status has been updated to accepted\n",
      "2025-07-23 16:43:43,179 INFO status has been updated to running\n"
     ]
    }
   ],
   "source": [
    "for ii, rcm in enumerate(rcms):\n",
    "    gcm = gcms[ii]\n",
    "    ens_member = ens_members[ii]\n",
    "    file = os.path.join(data_folder_catch, 'download.zip')\n",
    "    dataset = \"sis-hydrology-variables-derived-projections\"\n",
    "    request = {\n",
    "        \"product_type\": \"essential_climate_variables\",\n",
    "        \"variable\": [\"river_discharge\"],\n",
    "        \"variable_type\": \"absolute_values\",\n",
    "        \"time_aggregation\": \"daily\",\n",
    "        \"experiment\": [\"historical\"],\n",
    "        \"hydrological_model\":   [\"e_hypecatch_m00\",\n",
    "                                \"e_hypecatch_m01\",\n",
    "                                \"e_hypecatch_m02\",\n",
    "                                \"e_hypecatch_m03\",\n",
    "                                \"e_hypecatch_m04\",\n",
    "                                \"e_hypecatch_m05\",\n",
    "                                \"e_hypecatch_m06\",\n",
    "                                \"e_hypecatch_m07\"],\n",
    "        \"rcm\": rcm,\n",
    "        \"gcm\": gcm,\n",
    "        \"ensemble_member\": ens_member,\n",
    "        \"period\": [\"2001_2005\"]\n",
    "    }\n",
    "    client.retrieve(dataset, request, file)\n",
    "\n",
    "    # Unzip the file that was just downloaded, and remove the zip file\n",
    "    with zipfile.ZipFile(file, 'r') as zObject:\n",
    "        zObject.extractall(path=data_folder_catch)\n",
    "    os.remove(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df41df94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_daily(ds):\n",
    "    filename = ds.encoding['source'].split(\"/\")[-1].split(\"\\\\\")[-1]\n",
    "    ds['gcm_rcm'] = f'{filename.split(\"_\")[4]}_{filename.split(\"_\")[7]}'\n",
    "    ds = ds.set_coords('gcm_rcm').expand_dims('gcm_rcm')\n",
    "\n",
    "    ds['catchmodel'] = filename.split(\"_\")[3]\n",
    "    ds = ds.set_coords('catchmodel').expand_dims('catchmodel')    \n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755941ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK\n",
    "files = glob(os.path.join(data_folder_catch, 'rdis_daymean_abs_E-HYPEcatch*-EUR-11_*_na_*_catch_v1.nc'))\n",
    "ds_monmean = xr.open_mfdataset(files, preprocess=preprocess_daily)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae708361",
   "metadata": {},
   "source": [
    "### Downloading river discharge timeseries - monthly means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cd2882",
   "metadata": {},
   "source": [
    "Next we will download the historical monthly means of river discharges for 1971-2000 from the E-HYPEcatch models which are useful for checking longer-term statistics of river discharges in the historical climate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f55179",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii, rcm in enumerate(rcms):\n",
    "    gcm = gcms[ii]\n",
    "    ens_member = ens_members[ii]\n",
    "    file = os.path.join(data_folder_catch, 'download.zip')\n",
    "    dataset = \"sis-hydrology-variables-derived-projections\"\n",
    "    request = {\n",
    "        \"product_type\": \"climate_impact_indicators\",\n",
    "        \"variable\": [\"river_discharge\"],\n",
    "        \"variable_type\": \"absolute_values\",\n",
    "        \"time_aggregation\": \"monthly_mean\",\n",
    "        \"experiment\": [\"historical\"],\n",
    "        \"hydrological_model\":   [\"e_hypecatch_m00\",\n",
    "                                \"e_hypecatch_m01\",\n",
    "                                \"e_hypecatch_m02\",\n",
    "                                \"e_hypecatch_m03\",\n",
    "                                \"e_hypecatch_m04\",\n",
    "                                \"e_hypecatch_m05\",\n",
    "                                \"e_hypecatch_m06\",\n",
    "                                \"e_hypecatch_m07\"],\n",
    "        \"rcm\": rcm,\n",
    "        \"gcm\": gcm,\n",
    "        \"ensemble_member\": ens_member,\n",
    "        \"period\": [\"1971_2000\"]\n",
    "    }\n",
    "    client.retrieve(dataset, request, file)\n",
    "\n",
    "    # Unzip the file that was just downloaded, and remove the zip file\n",
    "    with zipfile.ZipFile(file, 'r') as zObject:\n",
    "        zObject.extractall(path=data_folder_catch)\n",
    "    os.remove(file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965d76a8",
   "metadata": {},
   "source": [
    "We will download monthly means of discharges for future periods of 2011-2040, 2041-2070 and 2071-2100:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f598ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii, rcm in enumerate(rcms):\n",
    "    gcm = gcms[ii]\n",
    "    ens_member = ens_members[ii]\n",
    "\n",
    "    for period in [\"2011_2040\",\"2041_2070\",\"2071_2100\"]:\n",
    "        file = os.path.join(data_folder_catch, 'download.zip')\n",
    "        dataset = \"sis-hydrology-variables-derived-projections\"\n",
    "        request = {\n",
    "            \"product_type\": \"climate_impact_indicators\",\n",
    "            \"variable\": [\"river_discharge\"],\n",
    "            \"variable_type\": \"absolute_values\",\n",
    "            \"time_aggregation\": \"monthly_mean\",\n",
    "            \"experiment\": [\"rcp_4_5\",\"rcp_8_5\"],\n",
    "            \"hydrological_model\":  [\"e_hypecatch_m00\",\n",
    "                                    \"e_hypecatch_m01\",\n",
    "                                    \"e_hypecatch_m02\",\n",
    "                                    \"e_hypecatch_m03\",\n",
    "                                    \"e_hypecatch_m04\",\n",
    "                                    \"e_hypecatch_m05\",\n",
    "                                    \"e_hypecatch_m06\",\n",
    "                                    \"e_hypecatch_m07\"],\n",
    "            \"rcm\": rcm,\n",
    "            \"gcm\": gcm,\n",
    "            \"ensemble_member\": ens_member,\n",
    "            \"period\": period\n",
    "        }\n",
    "        client.retrieve(dataset, request, file)\n",
    "\n",
    "        # Unzip the file that was just downloaded, and remove the zip file\n",
    "        with zipfile.ZipFile(file, 'r') as zObject:\n",
    "            zObject.extractall(path=data_folder_catch)\n",
    "        os.remove(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5dbd647",
   "metadata": {},
   "source": [
    "We will make use of a preprocessing function to write model names and scenarios to the dataset dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53910a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_monthly_mean(ds):\n",
    "    filename = ds.encoding['source'].split(\"/\")[-1].split(\"\\\\\")[-1]\n",
    "    ds['gcm_rcm'] = f'{filename.split(\"_\")[4]}_{filename.split(\"_\")[7]}'\n",
    "    ds = ds.set_coords('gcm_rcm').expand_dims('gcm_rcm')\n",
    "\n",
    "    ds['catchmodel'] = filename.split(\"_\")[3]\n",
    "    ds = ds.set_coords('catchmodel').expand_dims('catchmodel')    \n",
    "\n",
    "    ds['scenarios'] = filename.split(\"_\")[5]\n",
    "    ds = ds.set_coords('scenarios').expand_dims('scenarios')\n",
    "\n",
    "    ds['time_period'] = filename.split(\"_\")[9]\n",
    "    ds = ds.set_coords('time_period').expand_dims('time_period')\n",
    "\n",
    "    ds['time'] = ds.time.dt.month\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8097f4b",
   "metadata": {},
   "source": [
    "Now we can read the dataset of monthly means of river discharges into a single dataset variable and save it on disk as one file for ease of future access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3f2358",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob(os.path.join(data_folder_catch, 'rdis_ymonmean_abs_E-HYPEcatch*-EUR-11_*_na_*_catch_v1.nc'))\n",
    "ds_monmean = xr.open_mfdataset(files, preprocess=preprocess_monthly_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee850e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_monmean.to_netcdf(data_folder_catch, 'rdis_ymonmean_abs_E-HYPEcatch_allmodels.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2dfc5b",
   "metadata": {},
   "source": [
    "### Downloading data on flood occurence (extreme river discharges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a8b80a",
   "metadata": {},
   "source": [
    "We will download river discharge data corresponding to the 50-year return period (extreme river discharges projected to be exceeded once in 50 years). Similarly to the timeseries data, we will download this data for different climate scenarios, timelines and catchment models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c1705d",
   "metadata": {},
   "source": [
    "Downloading 50-year return period river discharges for the historical climate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99d1802",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii, rcm in enumerate(rcms):\n",
    "    gcm = gcms[ii]\n",
    "    ens_member = ens_members[ii]\n",
    "    \n",
    "    for period in [\"2011_2040\",\"2041_2070\",\"2071_2100\"]:\n",
    "        file = os.path.join(data_folder_catch, 'download.zip')\n",
    "        dataset = \"sis-hydrology-variables-derived-projections\"\n",
    "        request = {\n",
    "            \"product_type\": \"climate_impact_indicators\",\n",
    "            \"variable\": [\"flood_recurrence_50_years_return_period\"],\n",
    "            \"variable_type\": \"absolute_values\",\n",
    "            \"time_aggregation\": \"annual_mean\",\n",
    "            \"experiment\": [\"historical\"],\n",
    "            \"hydrological_model\": [\"e_hypecatch_m00\",\n",
    "                                    \"e_hypecatch_m01\",\n",
    "                                    \"e_hypecatch_m02\",\n",
    "                                    \"e_hypecatch_m03\",\n",
    "                                    \"e_hypecatch_m04\",\n",
    "                                    \"e_hypecatch_m05\",\n",
    "                                    \"e_hypecatch_m06\",\n",
    "                                    \"e_hypecatch_m07\"],\n",
    "            \"rcm\": rcm,\n",
    "            \"gcm\": gcm,\n",
    "            \"ensemble_member\": ens_member,\n",
    "            \"period\": period\n",
    "        }   \n",
    "        client.retrieve(dataset, request, file)\n",
    "\n",
    "        # Unzip the file that was just downloaded, and remove the zip file\n",
    "        with zipfile.ZipFile(file, 'r') as zObject:\n",
    "            zObject.extractall(path=data_folder_catch)\n",
    "        os.remove(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2327bb0d",
   "metadata": {},
   "source": [
    "Downloading 50-year return period river discharges for the future time periods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f56564",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii, rcm in enumerate(rcms):\n",
    "    gcm = gcms[ii]\n",
    "    ens_member = ens_members[ii]\n",
    "\n",
    "    for period in [\"2011_2040\",\"2041_2070\",\"2071_2100\"]:\n",
    "        file = os.path.join(data_folder_catch, 'download.zip')\n",
    "        dataset = \"sis-hydrology-variables-derived-projections\"\n",
    "        request = {\n",
    "            \"product_type\": \"climate_impact_indicators\",\n",
    "            \"variable\": [\"flood_recurrence_50_years_return_period\"],\n",
    "            \"variable_type\": \"absolute_values\",\n",
    "            \"time_aggregation\": \"annual_mean\",\n",
    "            \"experiment\": [\"rcp_4_5\",\"rcp_8_5\"],\n",
    "            \"hydrological_model\":  [\"e_hypecatch_m00\",\n",
    "                                    \"e_hypecatch_m01\",\n",
    "                                    \"e_hypecatch_m02\",\n",
    "                                    \"e_hypecatch_m03\",\n",
    "                                    \"e_hypecatch_m04\",\n",
    "                                    \"e_hypecatch_m05\",\n",
    "                                    \"e_hypecatch_m06\",\n",
    "                                    \"e_hypecatch_m07\"],\n",
    "            \"rcm\": rcm,\n",
    "            \"gcm\": gcm,\n",
    "            \"ensemble_member\": ens_member,\n",
    "            \"period\": period\n",
    "        }   \n",
    "        client.retrieve(dataset, request, file)\n",
    "\n",
    "        # Unzip the file that was just downloaded, and remove the zip file\n",
    "        with zipfile.ZipFile(file, 'r') as zObject:\n",
    "            zObject.extractall(path=data_folder_catch)\n",
    "        os.remove(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc63f36",
   "metadata": {},
   "source": [
    "We will make use of a preprocessing function to write model names and scenarios to the dataset dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f93680b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_add_gcm_scenarios(ds):\n",
    "    filename = ds.encoding['source'].split(\"/\")[-1].split(\"\\\\\")[-1]\n",
    "    ds['gcm_rcm'] = f'{filename.split(\"_\")[4]}_{filename.split(\"_\")[7]}'\n",
    "    ds = ds.set_coords('gcm_rcm').expand_dims('gcm_rcm')\n",
    "\n",
    "    ds['scenarios'] = filename.split(\"_\")[5]\n",
    "    ds = ds.set_coords('scenarios').expand_dims('scenarios')\n",
    "\n",
    "    time_period = [filename.split(\"_\")[9]]\n",
    "    ds = ds.assign_coords(time_period=(\"time\",time_period))\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bfffe9",
   "metadata": {},
   "source": [
    "We will read the dataset of extreme river discharges into a single dataset variable and save it on disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "aafd2cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob(os.path.join(data_folder_catch, 'rdisreturnmax50_tmean_abs_E-HYPEcatch*_catch_v1.nc'))\n",
    "ds_flood = xr.open_mfdataset(files, preprocess=preprocess_add_gcm_scenarios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad22e175",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_flood.to_netcdf(data_folder_catch, 'rdisreturnmax50_tmean_abs_E-HYPEcatch_allmodels.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079e2c31",
   "metadata": {},
   "source": [
    "Author of the workflow:  \n",
    "Natalia Aleksandrova (Deltares)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climaax_floods",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
